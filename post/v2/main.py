# =========================
# MAIN (multi-container friendly)
# =========================
import os, sys, time, urllib.parse, signal
from pathlib import Path
from datetime import datetime
from typing import Optional

# --- your project imports ---
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from logs.loging_config import logger
from util.startdriverproxy import bootstrap_auth, start_driver_with_proxy
from automation import install_early_hook, wait_next_req
from checkpoint import load_checkpoint, normalize_seen_ids, save_checkpoint
from get_posts_fb_automation import paginate_window, run_cursor_only
from utils import (
    get_vars_from_form, is_group_feed_req, make_vars_template,
    parse_form, update_vars_for_next_cursor
)

# ---------------------------
# Helpers: env + args
# ---------------------------
def env(key: str, default: Optional[str] = None, cast=str):
    v = os.environ.get(key, default)
    if v is None:
        return None
    if cast is bool:
        return str(v).lower() in ("1", "true", "yes", "y", "on")
    try:
        return cast(v)
    except Exception:
        return default

def add_common_args(ap):
    ap.add_argument("--group-url", type=str, default=env("GROUP_URL", "https://www.facebook.com/thoibao.de"))
    ap.add_argument("--page-name", type=str, default=env("PAGE_NAME", "thoibaode"))
    ap.add_argument("--account-tag", type=str, default=env("ACCOUNT_TAG", ""), help="Nh√£n ƒë·ªÉ t√°ch d·ªØ li·ªáu theo account (vd: acc01)")
    ap.add_argument("--data-root", type=str, default=env("DATA_ROOT", str(PROJECT_ROOT / "database")), help="Th∆∞ m·ª•c g·ªëc database (trong container n√™n mount v√†o /app/database)")
    ap.add_argument("--cookies-path", type=str, default=env("COOKIE_PATH", ""), help="ƒê∆∞·ªùng d·∫´n file cookies.json trong container")
    ap.add_argument("--keep-last", type=int, default=env("KEEP_LAST", 350, int))
    ap.add_argument("--mitm-port", type=int, default=env("MITM_PORT", 8899, int))
    ap.add_argument("--proxy-host", type=str, default=env("PROXY_HOST", ""))
    ap.add_argument("--proxy-port", type=int, default=env("PROXY_PORT", 0, int))
    ap.add_argument("--proxy-user", type=str, default=env("PROXY_USER", ""))
    ap.add_argument("--proxy-pass", type=str, default=env("PROXY_PASS", ""))

    ap.add_argument("--headless", action="store_true", help="Ch·∫°y headless (∆∞u ti√™n n·∫øu set)")
    ap.add_argument("--no-headless", action="store_true", help="T·∫Øt headless n·∫øu mu·ªën xem tr√¨nh duy·ªát")
    ap.add_argument("--resume", action="store_true", help="Ti·∫øp t·ª•c t·ª´ cursor trong checkpoint thay v√¨ b√°m head.")
    ap.add_argument("--page-limit", type=int, default=env("PAGE_LIMIT", None, int), help="Gi·ªõi h·∫°n s·ªë trang ƒë·ªÉ test (None = kh√¥ng gi·ªõi h·∫°n).")

    # backfill theo th√°ng
    ap.add_argument("--backfill", action="store_true", help="Crawl ng∆∞·ª£c theo time-slice.")
    ap.add_argument("--from-month", type=int, default=env("FROM_MONTH", None, int))
    ap.add_argument("--to-month", type=int, default=env("TO_MONTH", None, int))
    ap.add_argument("--year", type=int, default=env("YEAR", None, int))

def compute_paths(data_root: Path, page_name: str, account_tag: str):
    """
    Tr·∫£ v·ªÅ b·ªô ƒë∆∞·ªùng d·∫´n ƒë√£ t√°ch bi·ªát:
      database/post/page/<page_name>[/ACC_<account_tag>]
      + posts_all.ndjson, checkpoint.json, raw_dump_posts/
    """
    base = data_root / "post" / "page" / page_name
    if account_tag:
        base = base / f"ACC_{account_tag}"

    out_ndjson   = base / "posts_all.ndjson"
    raw_dump_dir = base / "raw_dump_posts"
    checkpoint   = base / "checkpoint.json"

    base.mkdir(parents=True, exist_ok=True)
    raw_dump_dir.mkdir(parents=True, exist_ok=True)
    out_ndjson.parent.mkdir(parents=True, exist_ok=True)
    return base, out_ndjson, raw_dump_dir, checkpoint

def make_headless(args) -> bool:
    # ∆Øu ti√™n flag CLI; n·∫øu kh√¥ng set, m·∫∑c ƒë·ªãnh headless=true trong container
    if args.headless:
        return True
    if args.no_headless:
        return False
    return True

# ---------------------------
# Graceful exit (SIGTERM)
# ---------------------------
_SHOULD_STOP = False
def _handle_sigterm(sig, frame):
    global _SHOULD_STOP
    _SHOULD_STOP = True
    logger.warning("[SIGNAL] Nh·∫≠n t√≠n hi·ªáu d·ª´ng, s·∫Ω tho√°t an to√†n sau b∆∞·ªõc hi·ªán t·∫°i.")
signal.signal(signal.SIGTERM, _handle_sigterm)
signal.signal(signal.SIGINT, _handle_sigterm)

# ---------------------------
# MAIN
# ---------------------------
if __name__ == "__main__":
    CLEANUP_JS = r"""
        (function(keep) {
        try {
            // ∆Øu ti√™n c√°c selector ƒë·∫∑c tr∆∞ng cho feed, tu·ª≥ giao di·ªán m√† ch·ªânh l·∫°i
            const selectors = [
            "div[data-pagelet^='FeedUnit_']", // nhi·ªÅu page d√πng
            "div[role='article']",
            "div[aria-posinset]"              // ƒë√¥i khi feed d√πng aria-posinset
            ];

            let posts = [];
            for (const sel of selectors) {
            posts = Array.from(document.querySelectorAll(sel));
            if (posts.length >= 10) {  // ƒë·ªß "t√≠n hi·ªáu" th√¨ d√πng selector n√†y
                break;
            }
            }

            const total = posts.length;
            const k = keep || 30;  // keep = s·ªë post gi·ªØ l·∫°i g·∫ßn nh·∫•t

            if (total > k) {
            const removeCount = total - k;
            for (let i = 0; i < removeCount; i++) {
                const el = posts[i];
                if (!el) continue;

                // N·∫øu post n·∫±m trong wrapper l·ªõn h∆°n th√¨ x√≥a wrapper lu√¥n cho s·∫°ch
                const story = el.closest("[data-testid='fbfeed_story']");
                if (story) {
                story.remove();
                } else {
                el.remove();
                }
            }
            // console.log("Cleanup DOM: removed", removeCount, "posts, keep", k);
            }
        } catch (e) {
            // console.error("Cleanup error", e);
        }
        })(arguments[0]);
        """

    import argparse
    ap = argparse.ArgumentParser("FB Post Crawler (multi-container safe)")
    add_common_args(ap)
    args = ap.parse_args()

    GROUP_URL   = args.group_url.strip()
    PAGE_NAME   = args.page_name.strip()
    ACCOUNT_TAG = (args.account_tag or "").strip()
    DATA_ROOT   = Path(args.data_root).resolve()
    COOKIES     = args.cookies_path.strip()
    KEEP_LAST   = int(args.keep_last)
    MITM_PORT   = int(args.mitm_port)

    # Kh·ªüi t·∫°o ƒë∆∞·ªùng d·∫´n t√°ch bi·ªát theo PAGE + ACCOUNT_TAG (tr√°nh ƒë·ª•ng khi ch·∫°y song song)
    DATABASE_PATH, OUT_NDJSON, RAW_DUMPS_DIR, CHECKPOINT = compute_paths(DATA_ROOT, PAGE_NAME, ACCOUNT_TAG)

    # Log banner ng·∫Øn ƒë·ªÉ ph√¢n bi·ªát container
    logger.info(f"[BOOT] PAGE={PAGE_NAME} | TAG={ACCOUNT_TAG or '-'} | MITM={MITM_PORT} | DATA_ROOT={DATA_ROOT}")
    logger.info(f"[PATH] DB={DATABASE_PATH} | OUT={OUT_NDJSON} | CKPT={CHECKPOINT}")

    # Kh·ªüi driver + proxy
    headless = make_headless(args)
    d = start_driver_with_proxy(
        proxy_host=args.proxy_host or None,
        proxy_port=args.proxy_port or None,
        proxy_user=args.proxy_user or None,
        proxy_pass=args.proxy_pass or None,
        mitm_port=MITM_PORT,
        headless=False
    )
    d.set_script_timeout(40)

    # B·∫≠t CDP t·ªëi ∆∞u cache
    try:
        d.execute_cdp_cmd("Network.enable", {})
        d.execute_cdp_cmd("Network.setCacheDisabled", {"cacheDisabled": True})
    except Exception:
        pass

    # Auth
    if COOKIES and os.path.exists(COOKIES):
        bootstrap_auth(d, COOKIES)
    else:
        logger.warning(f"[AUTH] Kh√¥ng t√¨m th·∫•y cookies: {COOKIES}")

    # Early hook
    try:
        install_early_hook(d, keep_last=KEEP_LAST)
    except Exception as e:
        logger.error("[WARN] install_early_hook: %s", e)

    # Load trang & b·∫Øt request feed
    d.get(GROUP_URL)
    time.sleep(1.5)

    # Tham s·ªë ƒëi·ªÅu ch·ªânh
    MAX_SCROLLS       = 10000        # upper bound
    CLEANUP_EVERY     = 25           # sau m·ªói 25 l·∫ßn scroll th√¨ d·ªçn DOM 1 l·∫ßn
    STALL_THRESHOLD   = 8            # n·∫øu scrollHeight kh√¥ng ƒë·ªïi 8 l·∫ßn li√™n ti·∫øp -> coi nh∆∞ h·∫øt b√†i

    prev_height       = None
    stall_count       = 0

    for i in range(MAX_SCROLLS):
        if _SHOULD_STOP:
            logger.info("[STOP] Received stop flag, breaking scroll loop.")
            break

        # Scroll th√™m ~0.9 m√†n h√¨nh
        try:
            d.execute_script("window.scrollBy(0, Math.floor(window.innerHeight * 0.9));")
        except Exception as e:
            logger.warning("[SCROLL] execute_script error: %s", e)
            break

        time.sleep(1.0)  # cho FB load th√™m

        # ƒê·ªãnh k·ª≥ d·ªçn DOM ƒë·ªÉ tr√°nh ph√¨nh to
        if i > 0 and (i % CLEANUP_EVERY == 0):
            try:
                d.execute_script(CLEANUP_JS, KEEP_LAST)
                logger.debug("[CLEANUP] DOM cleanup executed at scroll #%d", i)
            except Exception as e:
                logger.debug("[CLEANUP] error: %s", e)

        # Check xem c√≥ c√≤n load th√™m content kh√¥ng b·∫±ng scrollHeight
        try:
            cur_height = d.execute_script("return document.body.scrollHeight;")
        except Exception as e:
            logger.debug("[HEIGHT] error: %s", e)
            cur_height = None

        if prev_height is not None and cur_height is not None:
            if cur_height <= prev_height:
                stall_count += 1
            else:
                stall_count = 0
                prev_height = cur_height
        else:
            prev_height = cur_height
            stall_count = 0

        if stall_count >= STALL_THRESHOLD:
            logger.info(
                "[END] No new content after %d consecutive scrolls (last height=%s). Stop.",
                stall_count, cur_height
            )
            break


    # nxt = wait_next_req(d, 0, is_group_feed_req, timeout=25, poll=0.25)
    # if not nxt:
    #     d.quit()
    #     raise RuntimeError("Kh√¥ng b·∫Øt ƒë∆∞·ª£c request feed. H√£y cu·ªôn th√™m/ki·ªÉm tra quy·ªÅn.")

    # _, first_req = nxt
    # form         = parse_form(first_req.get("body", ""))
    # friendly     = urllib.parse.parse_qs(first_req.get("body","")).get("fb_api_req_friendly_name", [""])[0]
    # vars_now     = get_vars_from_form(form)
    # template_now = make_vars_template(vars_now)

    # # Checkpoint ri√™ng (theo PAGE + TAG)
    # state = load_checkpoint(CHECKPOINT)
    # seen_ids      = normalize_seen_ids(state.get("seen_ids"))
    # cursor_ckpt   = state.get("cursor")
    # vars_template = state.get("vars_template") or template_now
    # effective_template = vars_template or template_now

    # # ---- BACKFILL MODE ----
    # if args.backfill and args.year and args.from_month and args.to_month:
    #     logger.info(f"[MODE] Backfill {args.from_month:02d}/{args.year} ‚Üí {args.to_month:02d}/{args.year}")
    #     cur = args.from_month
    #     while cur >= args.to_month:
    #         start_dt = datetime(args.year, cur, 1)
    #         if cur == 1:
    #             end_dt = datetime(args.year - 1, 12, 1)
    #         else:
    #             end_dt = datetime(args.year, cur - 1, 1)

    #         t_from = int(end_dt.timestamp())
    #         t_to   = int(start_dt.timestamp())

    #         logger.info(f"üï∞Ô∏è Crawling tr∆∞·ªõc {start_dt.strftime('%Y-%m-%d')} ...")
    #         total_new, min_created, has_next = paginate_window(
    #             d, form, effective_template,
    #             seen_ids=set(),               # backfill theo slice -> kh√¥ng d√πng seen chung
    #             t_from=t_from,
    #             t_to=t_to,
    #             group_url=GROUP_URL,
    #             database_path=DATABASE_PATH,
    #             page_limit=args.page_limit
    #         )
    #         logger.info(f"‚úÖ Done {start_dt.strftime('%Y-%m')} ‚Üí {total_new} posts | min_created={min_created}")
    #         save_checkpoint(
    #             cursor=None,
    #             seen_ids=list(seen_ids),
    #             vars_template=effective_template,
    #             mode="time",
    #             slice_from=None,
    #             slice_to=t_to,
    #             year=args.year,
    #             check_point_path=CHECKPOINT
    #         )
    #         if _SHOULD_STOP:
    #             logger.warning("[STOP] Nh·∫≠n t√≠n hi·ªáu d·ª´ng gi·ªØa backfill ‚Äî tho√°t an to√†n.")
    #             break
    #         time.sleep(2)
    #         cur -= 1

    #     logger.info("üéâ [DONE] Backfill completed.")
    #     d.quit()
    #     sys.exit(0)

    # # ---- RESUME cursor-only ----
    # if args.resume and cursor_ckpt:
    #     form = update_vars_for_next_cursor(form, cursor_ckpt, vars_template=effective_template)
    #     logger.info(f"[RESUME] D√πng l·∫°i cursor: {str(cursor_ckpt)[:40]}...")

    # total_got = run_cursor_only(
    #     d,
    #     form,
    #     effective_template,
    #     seen_ids,
    #     database_path=DATABASE_PATH,
    #     page_limit=args.page_limit,
    #     resume=args.resume
    # )

    # # L∆∞u checkpoint cu·ªëi (per PAGE+TAG)
    # save_checkpoint(
    #     cursor=None,
    #     seen_ids=list(seen_ids),
    #     vars_template=effective_template,
    #     mode=None, slice_from=None, slice_to=None, year=None,
    #     check_point_path=CHECKPOINT
    # )
    # logger.info(f"[DONE] total new written (cursor-only) = {total_got} ‚Üí {OUT_NDJSON}")
    # d.quit()
